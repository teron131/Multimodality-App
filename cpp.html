<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="cache-control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="pragma" content="no-cache">
    <meta http-equiv="expires" content="0">
    <title>AudioInsight-CPP Prototype - RELOAD 20250606_062806</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        
        .container {
            background: white;
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        
        h1 {
            color: #333;
            text-align: center;
            margin-bottom: 30px;
        }
        
        .status {
            text-align: center;
            margin-bottom: 20px;
            padding: 10px;
            border-radius: 5px;
            font-weight: bold;
        }
        
        .status.ready { background-color: #d4edda; color: #155724; }
        .status.recording { background-color: #fff3cd; color: #856404; }
        .status.processing { background-color: #cce7ff; color: #004085; }
        .status.error { background-color: #f8d7da; color: #721c24; }
        
        .controls {
            text-align: center;
            margin-bottom: 30px;
        }
        
        button {
            padding: 12px 24px;
            margin: 10px;
            border: none;
            border-radius: 5px;
            font-size: 16px;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        .record-btn {
            background-color: #dc3545;
            color: white;
        }
        
        .record-btn:hover {
            background-color: #c82333;
        }
        
        .record-btn:disabled {
            background-color: #6c757d;
            cursor: not-allowed;
        }
        
        .stop-btn {
            background-color: #6c757d;
            color: white;
        }
        
        .stop-btn:hover {
            background-color: #5a6268;
        }
        
        .test-btn {
            background-color: #007bff;
            color: white;
        }
        
        .test-btn:hover {
            background-color: #0056b3;
        }
        
        .output {
            background-color: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 5px;
            padding: 20px;
            margin-top: 20px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
            white-space: pre-wrap;
            font-family: 'Courier New', monospace;
        }
        
        .server-info {
            background-color: #e9ecef;
            border-radius: 5px;
            padding: 15px;
            margin-bottom: 20px;
        }
        
        .audio-info {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin-bottom: 20px;
        }
        
        .info-card {
            background-color: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 5px;
            padding: 15px;
        }
        
        .info-card h3 {
            margin-top: 0;
            color: #495057;
        }
        
        .recording-indicator {
            display: inline-block;
            width: 10px;
            height: 10px;
            background-color: #dc3545;
            border-radius: 50%;
            margin-left: 10px;
            animation: blink 1s infinite;
        }
        
        @keyframes blink {
            0%, 50% { opacity: 1; }
            51%, 100% { opacity: 0; }
        }
        
        .hidden {
            display: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è AudioInsight-CPP Prototype - RELOAD 20250606_062806</title>
        <div class="subtitle" style="text-align: center; color: #666; margin-bottom: 30px;">
            Exploring llama.cpp with Ultravox multimodal audio+text processing
        </div>
        
        <div class="server-info">
            <h3>üñ•Ô∏è Server Configuration</h3>
            <p><strong>Model:</strong> ultravox-v0_5-llama-3_2-1b-GGUF</p>
            <p><strong>Endpoint:</strong> http://127.0.0.1:8081</p>
            <p><strong>Status:</strong> <span id="serverStatus">Checking...</span></p>
        </div>
        
        <div class="status ready" id="statusDiv">Ready to record</div>
        
        <div class="controls">
            <button class="record-btn" id="recordBtn" onclick="startRecording()">
                üéôÔ∏è Start Recording
            </button>
            <button class="stop-btn" id="stopBtn" onclick="stopRecording()" disabled>
                ‚èπÔ∏è Stop Recording
            </button>
            <button class="test-btn" onclick="testServer()">
                üîç Test Server
            </button>
        </div>
        
        <div class="audio-info">
            <div class="info-card">
                <h3>üìä Recording Info</h3>
                <p>Duration: <span id="duration">0s</span></p>
                <p>Sample Rate: <span id="sampleRate">-</span></p>
                <p>Channels: <span id="channels">-</span></p>
            </div>
            <div class="info-card">
                <h3>üéµ Audio Format</h3>
                <p>Format: WAV (16-bit PCM)</p>
                <p>Target Rate: 16kHz</p>
                <p>Processing: Real-time</p>
            </div>
        </div>
        
        <div class="output" id="output">Transcript and analysis will appear here...\n\nüìù Instructions:\n1. Click "Test Server" to verify llama-server connection\n2. Click "Start Recording" to begin audio capture\n3. Speak clearly into your microphone\n4. Click "Stop Recording" to process the audio\n5. View the multimodal analysis results below</div>
    </div>

    <script>
        let mediaRecorder;
        let recordedChunks = [];
        let startTime;
        let durationInterval;
        
        // Check server status on load
        window.addEventListener('load', function() {
            testServer();
        });
        
        async function testServer() {
            const statusSpan = document.getElementById('serverStatus');
            const output = document.getElementById('output');
            
            try {
                statusSpan.textContent = 'Testing...';
                output.textContent += '\nüîç Testing server connection...\n';
                
                const response = await fetch('http://127.0.0.1:8081/health');
                const data = await response.json();
                
                if (response.ok) {
                    statusSpan.textContent = '‚úÖ Online';
                    statusSpan.style.color = '#28a745';
                    output.textContent += `‚úÖ Server is healthy\nResponse: ${JSON.stringify(data, null, 2)}\n`;
                } else {
                    throw new Error(`HTTP ${response.status}`);
                }
            } catch (error) {
                statusSpan.textContent = '‚ùå Offline';
                statusSpan.style.color = '#dc3545';
                output.textContent += `‚ùå Server test failed: ${error.message}\n`;
                output.textContent += 'üí° Make sure llama-server is running on port 8081\n';
            }
        }
        
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    } 
                });
                
                // Update UI
                updateStatus('recording', 'üî¥ Recording...');
                document.getElementById('recordBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                
                // Update audio info
                const audioTrack = stream.getAudioTracks()[0];
                const settings = audioTrack.getSettings();
                document.getElementById('sampleRate').textContent = `${settings.sampleRate}Hz`;
                document.getElementById('channels').textContent = settings.channelCount || 1;
                
                // Start recording
                recordedChunks = [];
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                
                mediaRecorder.ondataavailable = function(event) {
                    if (event.data.size > 0) {
                        recordedChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = function() {
                    stream.getTracks().forEach(track => track.stop());
                    processAudio();
                };
                
                mediaRecorder.start();
                startTime = Date.now();
                
                // Update duration counter
                durationInterval = setInterval(() => {
                    const elapsed = Math.floor((Date.now() - startTime) / 1000);
                    document.getElementById('duration').textContent = `${elapsed}s`;
                }, 1000);
                
                document.getElementById('output').textContent += '\nüéôÔ∏è Recording started...\n';
                
            } catch (error) {
                updateStatus('error', '‚ùå Error accessing microphone');
                document.getElementById('output').textContent += `\n‚ùå Microphone error: ${error.message}\n`;
                console.error('Error accessing microphone:', error);
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                clearInterval(durationInterval);
                
                updateStatus('processing', '‚è≥ Processing audio...');
                document.getElementById('recordBtn').disabled = false;
                document.getElementById('stopBtn').disabled = true;
                
                document.getElementById('output').textContent += '‚èπÔ∏è Recording stopped, processing...\n';
            }
        }
        
        async function processAudio() {
            try {
                // Create blob from recorded chunks
                const audioBlob = new Blob(recordedChunks, { type: 'audio/webm;codecs=opus' });
                
                document.getElementById('output').textContent += `üìÅ Audio blob created: ${audioBlob.size} bytes\n`;
                
                // Extract audio data directly
                const audioData = await convertToAudio(audioBlob);
                
                // Send to llama-server
                await sendToServer(audioData);
                
            } catch (error) {
                updateStatus('error', '‚ùå Processing failed');
                document.getElementById('output').textContent += `\n‚ùå Processing error: ${error.message}\n`;
                console.error('Processing error:', error);
            }
        }
        
        async function convertToAudio(audioBlob) {
            return new Promise((resolve, reject) => {
                const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                const reader = new FileReader();
                
                reader.onload = async function(e) {
                    try {
                        const arrayBuffer = e.target.result;
                        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                        
                        // Extract mono audio data at 16kHz
                        let finalAudioData;
                        if (audioBuffer.sampleRate !== 16000) {
                            // Simple resampling for 16kHz
                            const ratio = audioBuffer.sampleRate / 16000;
                            const newLength = Math.floor(audioBuffer.length / ratio);
                            finalAudioData = new Float32Array(newLength);
                            
                            for (let i = 0; i < newLength; i++) {
                                const sourceIndex = Math.floor(i * ratio);
                                finalAudioData[i] = audioBuffer.getChannelData(0)[sourceIndex];
                            }
                        } else {
                            finalAudioData = audioBuffer.getChannelData(0);
                        }
                        
                        // Check if audio has content
                        let maxAmplitude = 0;
                        for (let i = 0; i < finalAudioData.length; i++) {
                            maxAmplitude = Math.max(maxAmplitude, Math.abs(finalAudioData[i]));
                        }
                        
                        const timestamp = new Date().toLocaleTimeString();
                        document.getElementById('output').textContent += `üîÑ [${timestamp}] v2.3 ANTI-HALLUCINATION: Extracted audio: ${finalAudioData.length} samples at 16kHz\n`;
                        document.getElementById('output').textContent += `üîä Audio amplitude check: max=${maxAmplitude.toFixed(4)} (${maxAmplitude > 0.01 ? 'GOOD' : 'WEAK/SILENT'})\n`;
                        
                        resolve(finalAudioData);
                        
                    } catch (error) {
                        reject(error);
                    }
                };
                
                reader.onerror = reject;
                reader.readAsArrayBuffer(audioBlob);
            });
        }
        
        async function tryMultipleFormats(audioData) {
            // Try different audio formats and API approaches
            const formats = [
                { name: "OpenAI input_audio format", func: () => tryOpenAIFormat(audioData) },
                { name: "Raw PCM data", func: () => tryRawFormat(audioData) },
                { name: "Proper WAV file format", func: () => tryFileUpload(audioData) }
            ];
            
            for (const format of formats) {
                try {
                    document.getElementById('output').textContent += `üîÑ Trying ${format.name}...\n`;
                    const success = await format.func();
                    if (success) {
                        return;
                    }
                } catch (error) {
                    document.getElementById('output').textContent += `‚ùå ${format.name} failed: ${error.message}\n`;
                }
            }
            
            document.getElementById('output').textContent += `‚ùå All audio formats failed\n`;
            updateStatus('error', '‚ùå All audio formats failed');
        }
        
        async function tryOpenAIFormat(audioData) {
            // Convert to base64 raw audio data (no WAV headers)
            const int16Data = new Int16Array(audioData.length);
            for (let i = 0; i < audioData.length; i++) {
                int16Data[i] = Math.max(-32768, Math.min(32767, audioData[i] * 32767));
            }
            
            // Convert to base64
            const bytes = new Uint8Array(int16Data.buffer);
            let audioBase64 = '';
            const chunkSize = 8192;
            for (let i = 0; i < bytes.length; i += chunkSize) {
                const chunk = bytes.slice(i, i + chunkSize);
                audioBase64 += btoa(String.fromCharCode(...chunk));
            }
            
            const requestBody = {
                model: "ultravox",
                messages: [
                    {
                        role: "user",
                        content: [
                            {
                                type: "text",
                                text: "Transcribe this audio and tell me what you hear."
                            },
                            {
                                type: "input_audio",
                                input_audio: {
                                    data: audioBase64,
                                    format: "wav"
                                }
                            }
                        ]
                    }
                ]
            };
            
            const response = await fetch('http://127.0.0.1:8081/v1/chat/completions', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(requestBody)
            });
            
            const responseText = await response.text();
            document.getElementById('output').textContent += `üì° OpenAI format response: ${response.status}\n`;
            
            if (response.ok) {
                const result = JSON.parse(responseText);
                displayResults(result);
                return true;
            } else {
                document.getElementById('output').textContent += `‚ùå OpenAI format failed: ${responseText}\n`;
                return false;
            }
        }
        
        async function tryRawFormat(audioData) {
            // Try sending as raw PCM data
            const requestBody = {
                model: "ultravox",
                prompt: "Transcribe this audio:",
                audio_data: Array.from(audioData),
                sample_rate: 16000
            };
            
            const response = await fetch('http://127.0.0.1:8081/v1/completions', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(requestBody)
            });
            
            const responseText = await response.text();
            document.getElementById('output').textContent += `üì° Raw format response: ${response.status}\n`;
            
            if (response.ok) {
                const result = JSON.parse(responseText);
                
                // Check if the response is hallucinated (contains fake content)
                const responseContent = result.choices?.[0]?.text || '';
                const isHallucination = responseContent.includes('podcast') || 
                                      responseContent.includes('Welcome to') || 
                                      responseContent.includes('economics') ||
                                      responseContent.length > 1000; // Very long responses are usually hallucinated
                
                if (isHallucination) {
                    document.getElementById('output').textContent += `‚ö†Ô∏è Raw format returned hallucinated content (not real transcription)\n`;
                    return false; // Continue trying other formats
                } else {
                    displayResults(result, true);
                    return true;
                }
            } else {
                document.getElementById('output').textContent += `‚ùå Raw format failed: ${responseText}\n`;
                return false;
            }
        }
        
        async function tryFileUpload(audioData) {
            // Try sending WAV as base64 with proper format
            const wavBlob = createWavBlob(audioData);
            const arrayBuffer = await wavBlob.arrayBuffer();
            const bytes = new Uint8Array(arrayBuffer);
            
            // Convert to base64 in chunks
            let audioBase64 = '';
            const chunkSize = 8192;
            for (let i = 0; i < bytes.length; i += chunkSize) {
                const chunk = bytes.slice(i, i + chunkSize);
                audioBase64 += btoa(String.fromCharCode(...chunk));
            }
            
            // Try with proper WAV format in chat completions
            const requestBody = {
                model: "ultravox",
                messages: [
                    {
                        role: "user",
                        content: [
                            {
                                type: "text",
                                text: "Transcribe this audio recording. Provide only the transcription, no additional commentary."
                            },
                            {
                                type: "input_audio",
                                input_audio: {
                                    data: audioBase64,
                                    format: "wav"
                                }
                            }
                        ]
                    }
                ],
                max_tokens: 100,
                temperature: 0.0
            };
            
            const response = await fetch('http://127.0.0.1:8081/v1/chat/completions', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(requestBody)
            });
            
            const responseText = await response.text();
            document.getElementById('output').textContent += `üì° WAV file response: ${response.status}\n`;
            
            if (response.ok) {
                const result = JSON.parse(responseText);
                
                // Check for hallucination
                const responseContent = result.choices?.[0]?.message?.content || '';
                const isHallucination = responseContent.includes('podcast') || 
                                      responseContent.includes('Welcome to') || 
                                      responseContent.includes('economics') ||
                                      responseContent.length > 500; // Long responses likely hallucinated
                
                if (isHallucination) {
                    document.getElementById('output').textContent += `‚ö†Ô∏è WAV format also returned hallucinated content\n`;
                    return false;
                } else {
                    displayResults(result);
                    return true;
                }
            } else {
                document.getElementById('output').textContent += `‚ùå WAV file format failed: ${responseText}\n`;
                return false;
            }
        }
        
        function createWavBlob(audioData) {
            // Create a proper WAV blob using Web API
            const sampleRate = 16000;
            const numChannels = 1;
            const bitsPerSample = 16;
            
            const length = audioData.length;
            const arrayBuffer = new ArrayBuffer(44 + length * 2);
            const view = new DataView(arrayBuffer);
            
            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + length * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * numChannels * bitsPerSample / 8, true);
            view.setUint16(32, numChannels * bitsPerSample / 8, true);
            view.setUint16(34, bitsPerSample, true);
            writeString(36, 'data');
            view.setUint32(40, length * 2, true);
            
            // Convert audio data
            let offset = 44;
            for (let i = 0; i < length; i++) {
                const sample = Math.max(-1, Math.min(1, audioData[i]));
                view.setInt16(offset, sample * 0x7FFF, true);
                offset += 2;
            }
            
            return new Blob([arrayBuffer], { type: 'audio/wav' });
        }
        

        
        async function sendToServer(audioData) {
            try {
                const timestamp = new Date().toLocaleTimeString();
                document.getElementById('output').textContent += `üì§ [${timestamp}] v2.3 ANTI-HALLUCINATION: Sending audio to llama-server...\n`;
                document.getElementById('output').textContent += `üîß Audio samples: ${audioData.length}, sample rate: 16kHz\n`;
                
                // Try multiple formats until one works
                await tryMultipleFormats(audioData);
                
            } catch (error) {
                document.getElementById('output').textContent += `‚ùå sendToServer error: ${error.message}\n`;
                updateStatus('error', '‚ùå Audio processing failed');
            }
        }
        
        
        

        
        function displayResults(result, isCompletion = false) {
            const output = document.getElementById('output');
            
            updateStatus('ready', '‚úÖ Processing complete');
            
            output.textContent += '\n' + '='.repeat(50) + '\n';
            output.textContent += 'üìã RESULTS:\n';
            output.textContent += '='.repeat(50) + '\n';
            
            if (isCompletion) {
                output.textContent += `ü§ñ Model Response:\n${result.content || result.text || 'No content received'}\n\n`;
            } else {
                if (result.choices && result.choices.length > 0) {
                    const choice = result.choices[0];
                    output.textContent += `ü§ñ Model Response:\n${choice.message?.content || choice.text || 'No content received'}\n\n`;
                }
            }
            
            output.textContent += `üìä Full Response:\n${JSON.stringify(result, null, 2)}\n`;
            output.textContent += '\n' + '='.repeat(50) + '\n';
            
            // Auto-scroll to bottom
            output.scrollTop = output.scrollHeight;
        }
        
        function updateStatus(type, message) {
            const statusDiv = document.getElementById('statusDiv');
            statusDiv.className = `status ${type}`;
            statusDiv.innerHTML = message + (type === 'recording' ? '<span class="recording-indicator"></span>' : '');
        }
    </script>
</body>
</html> 