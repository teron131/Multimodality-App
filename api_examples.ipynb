{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatOpenAI</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">client</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">openai.resources.chat.completions.completions.Completions</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f352da326f0</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">async_client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;openai.resources.chat.completions.completions.AsyncCompletions object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f352dc34b00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">root_client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;openai.OpenAI object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f352e061e20</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">root_async_client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;openai.AsyncOpenAI object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f352da8c5c0</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'google/gemini-2.5-flash-preview-05-20'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">openai_api_key</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SecretStr</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'**********'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">openai_api_base</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://openrouter.ai/api/v1'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatOpenAI\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mclient\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mopenai.resources.chat.completions.completions.Completions\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7f352da326f0\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33masync_client\u001b[0m\u001b[39m=<openai.resources.chat.completions.completions.AsyncCompletions object at \u001b[0m\u001b[1;36m0x7f352dc34b00\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mroot_client\u001b[0m\u001b[39m=<openai.OpenAI object at \u001b[0m\u001b[1;36m0x7f352e061e20\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mroot_async_client\u001b[0m\u001b[39m=<openai.AsyncOpenAI object at \u001b[0m\u001b[1;36m0x7f352da8c5c0\u001b[0m\u001b[1m>\u001b[0m,\n",
       "    \u001b[33mmodel_name\u001b[0m=\u001b[32m'google/gemini-2.5-flash-preview-05-20'\u001b[0m,\n",
       "    \u001b[33mmodel_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mopenai_api_key\u001b[0m=\u001b[1;35mSecretStr\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'**********'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mopenai_api_base\u001b[0m=\u001b[32m'https://openrouter.ai/api/v1'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"google/gemini-2.5-flash-preview-05-20\",\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "import ffmpeg\n",
    "\n",
    "SUPPORTED_IMAGE_FORMATS = {\".png\", \".jpeg\", \".jpg\", \".webp\", \".heic\", \".heif\"}\n",
    "SUPPORTED_AUDIO_FORMATS = {\".wav\", \".mp3\", \".aiff\", \".aac\", \".ogg\", \".flac\"}\n",
    "\n",
    "\n",
    "def encode_image(image_path: str | Path) -> str:\n",
    "    \"\"\"Convert image file to base64-encoded string.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the input image file\n",
    "\n",
    "    Returns:\n",
    "        Base64-encoded image data as string\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If image format is not supported\n",
    "    \"\"\"\n",
    "    image_path = Path(image_path)\n",
    "\n",
    "    if image_path.suffix.lower() not in SUPPORTED_IMAGE_FORMATS:\n",
    "        raise ValueError(f\"Unsupported image format: {image_path.suffix}. Supported formats: PNG, JPEG, WEBP, HEIC, HEIF\")\n",
    "\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def encode_audio(audio_path: str | Path) -> str:\n",
    "    \"\"\"Convert audio file to base64-encoded audio data.\n",
    "\n",
    "    Handles supported Gemini audio formats directly (WAV, MP3, AIFF, AAC, OGG, FLAC),\n",
    "    converts other formats to MP3 in memory using ffmpeg, then returns base64-encoded audio data.\n",
    "\n",
    "    Args:\n",
    "        audio_path: Path to the input audio file\n",
    "\n",
    "    Returns:\n",
    "        Base64-encoded audio data as string\n",
    "    \"\"\"\n",
    "    audio_path = Path(audio_path)\n",
    "\n",
    "    if audio_path.suffix.lower() in SUPPORTED_AUDIO_FORMATS:\n",
    "        with open(audio_path, \"rb\") as audio_file:\n",
    "            audio_data = audio_file.read()\n",
    "    else:\n",
    "        # Convert other formats to MP3 in memory\n",
    "        try:\n",
    "            out, err = ffmpeg.input(str(audio_path)).output(\"pipe:\", format=\"mp3\", acodec=\"libmp3lame\", audio_bitrate=\"192k\").run(capture_stdout=True, capture_stderr=True)\n",
    "            audio_data = out\n",
    "        except ffmpeg.Error as e:\n",
    "            raise RuntimeError(f\"FFmpeg conversion failed: {e.stderr.decode() if e.stderr else str(e)}\") from e\n",
    "\n",
    "    # Encode to base64\n",
    "    return base64.b64encode(audio_data).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# def encode_audio(audio_path):\n",
    "#     with open(audio_path, \"rb\") as audio_file:\n",
    "#         return base64.b64encode(audio_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "image_path = \"image/150920049.png\"\n",
    "image_base64 = encode_image(image_path)\n",
    "\n",
    "audio_path = \"audio/sXoSILzgFug.m4a\"\n",
    "audio_base64 = encode_audio(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    ")\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash-preview-05-20\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What do you see and hear?\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"}},\n",
    "                {\"type\": \"input_audio\", \"input_audio\": {\"data\": audio_base64, \"format\": \"mp3\"}},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**What I see:**\n",
       "\n",
       "I see a circular sticker with a teal or turquoise green background. On the sticker, there's a black silhouette of a\n",
       "cartoon sloth's head. The sloth has a friendly, smiling expression with small, round eyes and a little curved \n",
       "mouth. Its head is somewhat shaggy, indicated by jagged lines around its outline. The bottom right corner of the \n",
       "sticker is peeled up, revealing a metallic silver adhesive backing underneath, and there's a subtle shadow cast by \n",
       "the sticker on a white surface.\n",
       "\n",
       "**What I hear:**\n",
       "\n",
       "I hear a male voice speaking in **Cantonese**. The speaker narrates at a steady pace, discussing symptoms and \n",
       "psychological aspects related to what is called <span style=\"color: #008000; text-decoration-color: #008000\">\"Degenerate Gambling Syndrome\"</span> or <span style=\"color: #008000; text-decoration-color: #008000\">\"Stock Speculation Syndrome.\"</span>\n",
       "\n",
       "The content can be summarized as:\n",
       "\n",
       "*   It starts by listing symptoms like shortness of breath, insomnia, restlessness, or worsening temper, suggesting\n",
       "these might indicate the syndrome.\n",
       "*   It then poses a question about why people might make money initially when playing with small amounts in stock \n",
       "speculation but lose control when betting big.\n",
       "*   The speaker attributes this behavior to being too nervous or worried, leading to quick reactions when winning \n",
       "but an inability to cut losses.\n",
       "*   The narration concludes by stating that this is entirely related to one's mindset and that the current video \n",
       "will conduct a test.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**What I see:**\n",
       "\n",
       "I see a circular sticker with a teal or turquoise green background. On the sticker, there's a black silhouette of a\n",
       "cartoon sloth's head. The sloth has a friendly, smiling expression with small, round eyes and a little curved \n",
       "mouth. Its head is somewhat shaggy, indicated by jagged lines around its outline. The bottom right corner of the \n",
       "sticker is peeled up, revealing a metallic silver adhesive backing underneath, and there's a subtle shadow cast by \n",
       "the sticker on a white surface.\n",
       "\n",
       "**What I hear:**\n",
       "\n",
       "I hear a male voice speaking in **Cantonese**. The speaker narrates at a steady pace, discussing symptoms and \n",
       "psychological aspects related to what is called \u001b[32m\"Degenerate Gambling Syndrome\"\u001b[0m or \u001b[32m\"Stock Speculation Syndrome.\"\u001b[0m\n",
       "\n",
       "The content can be summarized as:\n",
       "\n",
       "*   It starts by listing symptoms like shortness of breath, insomnia, restlessness, or worsening temper, suggesting\n",
       "these might indicate the syndrome.\n",
       "*   It then poses a question about why people might make money initially when playing with small amounts in stock \n",
       "speculation but lose control when betting big.\n",
       "*   The speaker attributes this behavior to being too nervous or worried, leading to quick reactions when winning \n",
       "but an inability to cut losses.\n",
       "*   The narration concludes by stating that this is entirely related to one's mindset and that the current video \n",
       "will conduct a test.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gemini-2.5-flash-preview-05-20\",\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    ")\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": \"What do you see and hear?\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"}},\n",
    "            {\"type\": \"input_audio\", \"input_audio\": {\"data\": audio_base64, \"format\": \"mp3\"}},\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
