<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multimodality App - Complete Showcase</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
        }
        
        header {
            text-align: center;
            color: white;
            margin-bottom: 30px;
        }

        h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .subtitle {
            font-size: 1.2rem;
            opacity: 0.9;
        }

        .main-content {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin-bottom: 30px;
        }

        .section {
            background: white;
            border-radius: 15px;
            padding: 25px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            backdrop-filter: blur(10px);
        }

        .section h2 {
            color: #4a5568;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .icon {
            font-size: 1.5rem;
        }

        .tabs {
            display: flex;
            border-bottom: 2px solid #e2e8f0;
            margin-bottom: 20px;
        }

        .tab {
            padding: 10px 20px;
            cursor: pointer;
            border: none;
            background: none;
            font-size: 1rem;
            color: #718096;
            transition: all 0.3s ease;
            border-bottom: 3px solid transparent;
        }

        .tab.active {
            color: #4299e1;
            border-bottom-color: #4299e1;
        }

        .tab-content {
            display: none;
        }

        .tab-content.active {
            display: block;
        }

        .form-group {
            margin-bottom: 20px;
        }

        label {
            display: block;
            margin-bottom: 8px;
            font-weight: 600;
            color: #4a5568;
        }

        input[type="file"],
        textarea,
        select {
            width: 100%;
            padding: 12px;
            border: 2px solid #e2e8f0;
            border-radius: 8px;
            font-size: 1rem;
            transition: border-color 0.3s ease;
        }

        input[type="file"]:focus,
        textarea:focus,
        select:focus {
            outline: none;
            border-color: #4299e1;
        }

        textarea {
            min-height: 100px;
            resize: vertical;
        }

        .btn {
            padding: 12px 24px;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            margin-right: 10px;
            margin-bottom: 10px;
        }
        
        .btn-primary {
            background: linear-gradient(135deg, #4299e1, #3182ce);
            color: white;
        }

        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(66, 153, 225, 0.4);
        }

        .btn-secondary {
            background: #e2e8f0;
            color: #4a5568;
        }

        .btn-secondary:hover {
            background: #cbd5e0;
        }

        .btn-danger {
            background: linear-gradient(135deg, #f56565, #e53e3e);
            color: white;
        }

        .btn-danger:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(245, 101, 101, 0.4);
        }

        .btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none !important;
        }
        
        .status-indicator {
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: 600;
            margin-bottom: 15px;
            text-align: center;
        }
        
        .status-ready {
            background: #c6f6d5;
            color: #22543d;
        }

        .status-processing {
            background: #fed7d7;
            color: #742a2a;
        }

        .status-connected {
            background: #bee3f8;
            color: #2a4365;
        }

        .output-section {
            grid-column: 1 / -1;
        }
        
        .output {
            background: #f7fafc;
            border: 2px solid #e2e8f0;
            border-radius: 8px;
            padding: 20px;
            min-height: 300px;
            max-height: 500px;
            overflow-y: auto;
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            line-height: 1.5;
            white-space: pre-wrap;
        }

        .recording-controls {
            display: flex;
            align-items: center;
            gap: 15px;
            margin-top: 15px;
        }

        .recording-time {
            font-weight: 600;
            color: #e53e3e;
            font-size: 1.1rem;
        }

        .realtime-messages {
            max-height: 200px;
            overflow-y: auto;
            border: 1px solid #e2e8f0;
            border-radius: 8px;
            padding: 10px;
            background: #f8f9fa;
            font-family: monospace;
            font-size: 0.8rem;
            margin-top: 10px;
        }

        .file-preview {
            margin-top: 10px;
            padding: 10px;
            background: #f8f9fa;
            border-radius: 8px;
            border: 1px solid #e2e8f0;
        }

        .file-info {
            font-size: 0.9rem;
            color: #6b7280;
        }

        .progress-bar {
            width: 100%;
            height: 6px;
            background: #e2e8f0;
            border-radius: 3px;
            overflow: hidden;
            margin: 10px 0;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #4299e1, #3182ce);
            width: 0%;
            transition: width 0.3s ease;
        }

        @media (max-width: 768px) {
            .main-content {
                grid-template-columns: 1fr;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .container {
                padding: 15px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üöÄ Multimodality App Showcase</h1>
            <p class="subtitle">Complete testing suite for all modalities and real-time capabilities</p>
        </header>

        <div class="main-content">
            <!-- Non-Realtime Testing Section -->
            <div class="section">
                <h2><span class="icon">üìÅ</span>Non-Realtime Processing</h2>
                
                <div class="tabs">
                    <button class="tab active" onclick="switchTab('upload', 'text')">üìù Text</button>
                    <button class="tab" onclick="switchTab('upload', 'audio')">üéµ Audio</button>
                    <button class="tab" onclick="switchTab('upload', 'image')">üñºÔ∏è Image</button>
                    <button class="tab" onclick="switchTab('upload', 'video')">üé¨ Video</button>
                    <button class="tab" onclick="switchTab('upload', 'multi')">üîó Multi</button>
                </div>

                <!-- Text Tab -->
                <div id="upload-text" class="tab-content active">
                    <div class="form-group">
                        <label for="textInput">Text Input:</label>
                        <textarea id="textInput" placeholder="Enter your text here for analysis...">Hello, this is a test message for the multimodality app.</textarea>
                    </div>
                    <button class="btn btn-primary" onclick="processText()">Analyze Text</button>
                </div>

                <!-- Audio Tab -->
                <div id="upload-audio" class="tab-content">
                    <div class="form-group">
                        <label for="audioFile">Upload Audio File:</label>
                        <input type="file" id="audioFile" accept="audio/*" onchange="previewFile('audio')">
                        <div id="audioPreview" class="file-preview" style="display: none;"></div>
                    </div>
                    <div class="form-group">
                        <label for="audioPrompt">Analysis Prompt:</label>
                        <textarea id="audioPrompt" placeholder="What should I analyze about this audio?">Transcribe this audio and provide insights about what you hear.</textarea>
                    </div>
                    <button class="btn btn-primary" onclick="processAudio()">Process Audio</button>
                    
                    <div class="recording-controls">
                        <button id="recordBtn" class="btn btn-danger" onclick="startRecording()">üéôÔ∏è Start Recording</button>
                        <button id="stopBtn" class="btn btn-secondary" onclick="stopRecording()" disabled>‚èπÔ∏è Stop</button>
                        <span id="recordingTime" class="recording-time">00:00</span>
                    </div>
                </div>

                <!-- Image Tab -->
                <div id="upload-image" class="tab-content">
                    <div class="form-group">
                        <label for="imageFile">Upload Image File:</label>
                        <input type="file" id="imageFile" accept="image/*" onchange="previewFile('image')">
                        <div id="imagePreview" class="file-preview" style="display: none;"></div>
                    </div>
                    <div class="form-group">
                        <label for="imagePrompt">Analysis Prompt:</label>
                        <textarea id="imagePrompt" placeholder="What should I analyze about this image?">Analyze this image and describe what you see in detail.</textarea>
                    </div>
                    <button class="btn btn-primary" onclick="processImage()">Process Image</button>
                </div>

                <!-- Video Tab -->
                <div id="upload-video" class="tab-content">
                    <div class="form-group">
                        <label for="videoFile">Upload Video File:</label>
                        <input type="file" id="videoFile" accept="video/*" onchange="previewFile('video')">
                        <div id="videoPreview" class="file-preview" style="display: none;"></div>
                    </div>
                    <div class="form-group">
                        <label for="videoPrompt">Analysis Prompt:</label>
                        <textarea id="videoPrompt" placeholder="What should I analyze about this video?">Analyze this video and describe what you see, including any actions or notable details.</textarea>
                    </div>
                    <button class="btn btn-primary" onclick="processVideo()">Process Video</button>
                </div>

                <!-- Multimodal Tab -->
                <div id="upload-multi" class="tab-content">
                    <div class="form-group">
                        <label for="multiAudio">Audio File (optional):</label>
                        <input type="file" id="multiAudio" accept="audio/*" onchange="previewFile('multiAudio')">
                        <div id="multiAudioPreview" class="file-preview" style="display: none;"></div>
                    </div>
                    <div class="form-group">
                        <label for="multiImage">Image File (optional):</label>
                        <input type="file" id="multiImage" accept="image/*" onchange="previewFile('multiImage')">
                        <div id="multiImagePreview" class="file-preview" style="display: none;"></div>
                    </div>
                    <div class="form-group">
                        <label for="multiPrompt">Analysis Prompt:</label>
                        <textarea id="multiPrompt" placeholder="What should I analyze about this multimodal content?">Analyze the provided content and provide comprehensive insights.</textarea>
                    </div>
                    <button class="btn btn-primary" onclick="processMultimodal()">Process Multimodal</button>
                </div>
            </div>

            <!-- Real-time Testing Section -->
            <div class="section">
                <h2><span class="icon">‚ö°</span>Real-time WebSocket</h2>
                
                <div class="status-indicator" id="wsStatus">
                    <span id="wsStatusText">Disconnected</span>
                </div>

                <div class="form-group">
                    <button id="connectBtn" class="btn btn-primary" onclick="connectWebSocket()">Connect WebSocket</button>
                    <button id="disconnectBtn" class="btn btn-secondary" onclick="disconnectWebSocket()" disabled>Disconnect</button>
                </div>

                <div class="tabs">
                    <button class="tab active" onclick="switchTab('realtime', 'text')">üìù Text</button>
                    <button class="tab" onclick="switchTab('realtime', 'audio')">üéµ Audio</button>
                    <button class="tab" onclick="switchTab('realtime', 'image')">üñºÔ∏è Image</button>
                    <button class="tab" onclick="switchTab('realtime', 'video')">üé¨ Video</button>
                </div>

                <!-- Realtime Text -->
                <div id="realtime-text" class="tab-content active">
                    <div class="form-group">
                        <label for="realtimeTextInput">Send Text Message:</label>
                        <textarea id="realtimeTextInput" placeholder="Type your message here...">Hello from the real-time interface!</textarea>
                    </div>
                    <button class="btn btn-primary" onclick="sendRealtimeText()" disabled id="sendTextBtn">Send Text</button>
                </div>

                <!-- Realtime Audio -->
                <div id="realtime-audio" class="tab-content">
                    <div class="form-group">
                        <label for="realtimeAudioFile">Upload Audio:</label>
                        <input type="file" id="realtimeAudioFile" accept="audio/*" disabled>
                    </div>
                    <button class="btn btn-primary" onclick="sendRealtimeAudio()" disabled id="sendAudioBtn">Send Audio</button>
                    
                    <div class="recording-controls">
                        <button id="realtimeRecordBtn" class="btn btn-danger" onclick="startRealtimeRecording()" disabled>üéôÔ∏è Live Record</button>
                        <button id="realtimeStopBtn" class="btn btn-secondary" onclick="stopRealtimeRecording()" disabled>‚èπÔ∏è Stop</button>
                    </div>
                </div>

                <!-- Realtime Image -->
                <div id="realtime-image" class="tab-content">
                    <div class="form-group">
                        <label for="realtimeImageFile">Upload Image:</label>
                        <input type="file" id="realtimeImageFile" accept="image/*" disabled>
                    </div>
                    <button class="btn btn-primary" onclick="sendRealtimeImage()" disabled id="sendImageBtn">Send Image</button>
                </div>

                <!-- Realtime Video -->
                <div id="realtime-video" class="tab-content">
                    <div class="form-group">
                        <label for="realtimeVideoFile">Upload Video:</label>
                        <input type="file" id="realtimeVideoFile" accept="video/*" disabled>
                    </div>
                    <div class="form-group">
                        <label for="realtimeVideoPrompt">Analysis Prompt:</label>
                        <textarea id="realtimeVideoPrompt" placeholder="What should I analyze about this video?" disabled>Analyze this video and describe what you see, including any actions or notable details.</textarea>
                    </div>
                    <button class="btn btn-primary" onclick="sendRealtimeVideo()" disabled id="sendVideoBtn">Send Video</button>
                    
                    <div style="margin-top: 15px;">
                        <h4>üñ•Ô∏è Screen Sharing</h4>
                        <button class="btn btn-secondary" onclick="startScreenShare()" disabled id="videoStreamBtn">üì∫ Share Screen</button>
                        <button class="btn btn-danger" onclick="stopScreenShare()" disabled id="videoDisconnectBtn">‚èπÔ∏è Stop Sharing</button>
                        <div id="videoStreamStatus" class="status-indicator" style="display: none;"></div>
                        <div style="margin-top: 10px;">
                            <label for="screenAnalysisPrompt">Screen Analysis Prompt:</label>
                            <textarea id="screenAnalysisPrompt" placeholder="What should I analyze about your screen?" style="width: 100%; height: 60px; margin-top: 5px;">Describe what you see on the screen and any notable changes or activities.</textarea>
                        </div>
                        <div style="margin-top: 10px;">
                            <label for="frameInterval">Analysis Interval:</label>
                            <select id="frameInterval" style="margin-left: 10px;">
                                <option value="1000">Every 1 second (High frequency)</option>
                                <option value="3000" selected>Every 3 seconds (Optimal)</option>
                                <option value="5000">Every 5 seconds (Balanced)</option>
                                <option value="10000">Every 10 seconds (Conservative)</option>
                                <option value="30000">Every 30 seconds (Minimal)</option>
                                <option value="60000">Every 1 minute (Monitoring)</option>
                            </select>
                        </div>
                        <div style="margin-top: 10px;">
                            <label for="imageQuality">Image Quality:</label>
                            <select id="imageQuality" style="margin-left: 10px;">
                                <option value="0.6">High compression (smaller files)</option>
                                <option value="0.75" selected>Balanced (recommended)</option>
                                <option value="0.85">High quality (larger files)</option>
                                <option value="0.95">Maximum quality</option>
                            </select>
                        </div>
                        <div style="margin-top: 10px;">
                            <label for="changeThreshold">Change Detection Sensitivity:</label>
                            <select id="changeThreshold" style="margin-left: 10px;">
                                <option value="1">Very sensitive (1% change)</option>
                                <option value="3">Sensitive (3% change)</option>
                                <option value="5" selected>Balanced (5% change)</option>
                                <option value="10">Conservative (10% change)</option>
                                <option value="20">Very conservative (20% change)</option>
                                <option value="0">Disabled (analyze all frames)</option>
                            </select>
                        </div>
                        <div style="margin-top: 10px;">
                            <button class="btn btn-secondary" onclick="testFrameCapture()" disabled id="testCaptureBtn" style="font-size: 0.9em;">üß™ Test Frame Capture</button>
                        </div>
                    </div>
                </div>

                <div class="realtime-messages" id="realtimeMessages">
                    WebSocket messages will appear here...
                </div>
            </div>
        </div>

        <!-- Output Section -->
        <div class="section output-section">
            <h2><span class="icon">üìä</span>Results & Output</h2>
            <div class="progress-bar" id="progressBar" style="display: none;">
                <div class="progress-fill" id="progressFill"></div>
            </div>
            <div class="output" id="output">
                üöÄ Multimodality App Showcase - Ready to test all functionality!
                
                üìã Available Tests:
                ================
                
                üìÅ Non-Realtime Processing:
                ‚Ä¢ Text Analysis - Direct text processing
                ‚Ä¢ Audio Upload/Recording - File upload or live recording
                ‚Ä¢ Image Analysis - Image upload and analysis  
                ‚Ä¢ Video Analysis - Video upload and processing
                ‚Ä¢ Multimodal - Combined audio + image processing
                
                ‚ö° Real-time WebSocket:
                ‚Ä¢ Live text messaging
                ‚Ä¢ Real-time audio streaming
                ‚Ä¢ Live image processing
                ‚Ä¢ Real-time video analysis
                ‚Ä¢ Live screen sharing & analysis
                ‚Ä¢ Bidirectional communication
                
                üîß System Status:
                ‚Ä¢ Backend: Loading...
                ‚Ä¢ WebSocket: Disconnected
                ‚Ä¢ All modalities supported
                
                Select a test above to begin!
            </div>
        </div>
    </div>

    <script>
        // Global variables
        let mediaRecorder;
        let recordedChunks = [];
        let recordingStartTime;
        let recordingInterval;
        let websocket = null;
        let isConnected = false;
        let realtimeMediaRecorder;
        let realtimeRecordedChunks = [];

        // Initialize the app
        document.addEventListener('DOMContentLoaded', function() {
            checkSystemStatus();
            
            // Add event listeners for file inputs
            const realtimeAudioFile = document.getElementById('realtimeAudioFile');
            const realtimeImageFile = document.getElementById('realtimeImageFile');
            const realtimeVideoFile = document.getElementById('realtimeVideoFile');
            
            if (realtimeAudioFile) {
                realtimeAudioFile.addEventListener('change', function() {
                    const file = this.files[0];
                    if (file) {
                        updateRealtimeMessage(`üéµ Audio file selected: ${file.name} (${(file.size / 1024 / 1024).toFixed(2)} MB)`);
                    }
                });
            }
            
            if (realtimeImageFile) {
                realtimeImageFile.addEventListener('change', function() {
                    const file = this.files[0];
                    if (file) {
                        updateRealtimeMessage(`üñºÔ∏è Image file selected: ${file.name} (${(file.size / 1024 / 1024).toFixed(2)} MB)`);
                    }
                });
            }
            
            if (realtimeVideoFile) {
                realtimeVideoFile.addEventListener('change', function() {
                    const file = this.files[0];
                    if (file) {
                        updateRealtimeMessage(`üé¨ Video file selected: ${file.name} (${(file.size / 1024 / 1024).toFixed(2)} MB, ${file.type})`);
                    }
                });
            }
        });

        // Tab switching functionality
        function switchTab(section, tabName) {
            // Hide all tab contents in the section
            const tabContents = document.querySelectorAll(`#${section}-text, #${section}-audio, #${section}-image, #${section}-video, #${section}-multi`);
            tabContents.forEach(content => {
                content.classList.remove('active');
            });

            // Remove active class from all tabs in the section
            const tabs = document.querySelectorAll(`[onclick*="${section}"]`);
            tabs.forEach(tab => {
                tab.classList.remove('active');
            });

            // Show selected tab content
            const selectedContent = document.getElementById(`${section}-${tabName}`);
            if (selectedContent) {
                selectedContent.classList.add('active');
            }

            // Add active class to clicked tab
            event.target.classList.add('active');
        }

        // System status check
        async function checkSystemStatus() {
            try {
                const response = await fetch('/api/status');
                const status = await response.json();
                updateOutput(`‚úÖ System Status: ${status.message}\nüîß Backend: ${status.backend}\n`);
            } catch (error) {
                updateOutput(`‚ùå System Status Error: ${error.message}\n`);
            }
        }

        // File preview functionality
        function previewFile(type) {
            const fileInput = document.getElementById(`${type}File` || `${type}`);
            const previewDiv = document.getElementById(`${type}Preview`);
            
            if (!fileInput || !previewDiv) return;
            
            const file = fileInput.files[0];
            if (file) {
                previewDiv.style.display = 'block';
                previewDiv.innerHTML = `
                    <div class="file-info">
                        <strong>üìÑ ${file.name}</strong><br>
                        üìè Size: ${(file.size / 1024 / 1024).toFixed(2)} MB<br>
                        üè∑Ô∏è Type: ${file.type}
                    </div>
                `;
            } else {
                previewDiv.style.display = 'none';
            }
        }

        // Output management
        function updateOutput(message, clear = false) {
            const output = document.getElementById('output');
            if (clear) {
                output.textContent = '';
            }
            output.textContent += `[${new Date().toLocaleTimeString()}] ${message}\n`;
            output.scrollTop = output.scrollHeight;
        }

        function showProgress() {
            document.getElementById('progressBar').style.display = 'block';
            document.getElementById('progressFill').style.width = '100%';
        }

        function hideProgress() {
            document.getElementById('progressBar').style.display = 'none';
            document.getElementById('progressFill').style.width = '0%';
        }

        // Non-realtime processing functions
        async function processText() {
            const text = document.getElementById('textInput').value;
            if (!text.trim()) {
                updateOutput('‚ùå Please enter some text to analyze.');
                return;
            }

            updateOutput('üìù Processing text input...', true);
            showProgress();

            try {
                // Using the LLM directly via a simple endpoint (we'll need to create this)
                const response = await fetch('/api/process-text', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        text: text,
                        prompt: 'Analyze this text and provide insights.'
                    })
                });

                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`Unable to process text. Please try again.`);
                }

                const result = await response.json();
                updateOutput(`‚úÖ Text Analysis Complete:\n${result.analysis || result.message}\n`);
            } catch (error) {
                updateOutput(`‚ùå Text Processing Error: ${error.message}\n`);
            } finally {
                hideProgress();
            }
        }

        async function processAudio() {
            const fileInput = document.getElementById('audioFile');
            const prompt = document.getElementById('audioPrompt').value;
            
            if (!fileInput.files[0]) {
                updateOutput('‚ùå Please select an audio file.');
                return;
            }

            updateOutput('üéµ Processing audio file...', true);
            showProgress();

            try {
                const formData = new FormData();
                formData.append('audio', fileInput.files[0]);
                formData.append('prompt', prompt);

                const response = await fetch('/api/process-audio-unified', {
                    method: 'POST',
                    body: formData
                });

                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`Unable to process audio file. Please check the file format and try again.`);
                }

                const result = await response.json();
                updateOutput(`‚úÖ Audio Processing Complete:\n${result.transcription}\n`);
            } catch (error) {
                updateOutput(`‚ùå Audio Processing Error: ${error.message}\n`);
            } finally {
                hideProgress();
            }
        }

        async function processImage() {
            const fileInput = document.getElementById('imageFile');
            const prompt = document.getElementById('imagePrompt').value;
            
            if (!fileInput.files[0]) {
                updateOutput('‚ùå Please select an image file.');
                return;
            }

            updateOutput('üñºÔ∏è Processing image file...', true);
            showProgress();

            try {
                const formData = new FormData();
                formData.append('image', fileInput.files[0]);
                formData.append('prompt', prompt);

                const response = await fetch('/api/process-image-unified', {
                    method: 'POST',
                    body: formData
                });

                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`Unable to process image file. Please check the file format and try again.`);
                }

                const result = await response.json();
                updateOutput(`‚úÖ Image Processing Complete:\n${result.analysis}\n`);
            } catch (error) {
                updateOutput(`‚ùå Image Processing Error: ${error.message}\n`);
            } finally {
                hideProgress();
            }
        }

        async function processVideo() {
            const fileInput = document.getElementById('videoFile');
            const prompt = document.getElementById('videoPrompt').value;
            
            if (!fileInput.files[0]) {
                updateOutput('‚ùå Please select a video file.');
                return;
            }

            updateOutput('üé¨ Processing video file...', true);
            showProgress();

            try {
                const formData = new FormData();
                formData.append('video', fileInput.files[0]);
                formData.append('prompt', prompt);

                const response = await fetch('/api/process-video-unified', {
                    method: 'POST',
                    body: formData
                });

                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`Unable to process video file. Please check the file format and try again.`);
                }

                const result = await response.json();
                updateOutput(`‚úÖ Video Processing Complete:\n${result.analysis}\n`);
            } catch (error) {
                updateOutput(`‚ùå Video Processing Error: ${error.message}\n`);
            } finally {
                hideProgress();
            }
        }

        async function processMultimodal() {
            const audioInput = document.getElementById('multiAudio');
            const imageInput = document.getElementById('multiImage');
            const prompt = document.getElementById('multiPrompt').value;
            
            if (!audioInput.files[0] && !imageInput.files[0]) {
                updateOutput('‚ùå Please select at least one file (audio or image).');
                return;
            }

            updateOutput('üîó Processing multimodal content...', true);
            showProgress();

            try {
                const formData = new FormData();
                if (audioInput.files[0]) {
                    formData.append('audio', audioInput.files[0]);
                }
                if (imageInput.files[0]) {
                    formData.append('image', imageInput.files[0]);
                }
                formData.append('prompt', prompt);

                const response = await fetch('/api/process-multimodal-unified', {
                    method: 'POST',
                    body: formData
                });

                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`Unable to process files. Please check the file formats and try again.`);
                }

                const result = await response.json();
                updateOutput(`‚úÖ Multimodal Processing Complete:\n${result.analysis}\n`);
            } catch (error) {
                updateOutput(`‚ùå Multimodal Processing Error: ${error.message}\n`);
            } finally {
                hideProgress();
            }
        }

        // Recording functionality
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                recordedChunks = [];
                mediaRecorder = new MediaRecorder(stream);
                
                mediaRecorder.ondataavailable = function(event) {
                    if (event.data.size > 0) {
                        recordedChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = function() {
                    stream.getTracks().forEach(track => track.stop());
                    processRecordedAudio();
                };
                
                mediaRecorder.start();
                recordingStartTime = Date.now();
                
                document.getElementById('recordBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                
                recordingInterval = setInterval(updateRecordingTime, 1000);
                updateOutput('üéôÔ∏è Recording started...\n');
                
            } catch (error) {
                updateOutput(`‚ùå Recording Error: ${error.message}\n`);
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                clearInterval(recordingInterval);
                
                document.getElementById('recordBtn').disabled = false;
                document.getElementById('stopBtn').disabled = true;
                document.getElementById('recordingTime').textContent = '00:00';
                
                updateOutput('‚èπÔ∏è Recording stopped, processing...\n');
            }
        }
        
        function updateRecordingTime() {
            const elapsed = Math.floor((Date.now() - recordingStartTime) / 1000);
            const minutes = Math.floor(elapsed / 60);
            const seconds = elapsed % 60;
            document.getElementById('recordingTime').textContent = 
                `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
        }

        async function processRecordedAudio() {
                const audioBlob = new Blob(recordedChunks, { type: 'audio/webm' });
            const prompt = document.getElementById('audioPrompt').value;
            
            showProgress();

            try {
                const formData = new FormData();
                formData.append('audio', audioBlob, 'recording.webm');
                formData.append('prompt', prompt);
                
                const response = await fetch('/api/process-audio-unified', {
                    method: 'POST',
                    body: formData
                });
                
                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`Unable to process recording. Please try recording again.`);
                }
                
                const result = await response.json();
                updateOutput(`‚úÖ Recording Processing Complete:\n${result.transcription}\n`);
            } catch (error) {
                updateOutput(`‚ùå Recording Processing Error: ${error.message}\n`);
            } finally {
                hideProgress();
            }
        }

        // WebSocket functionality
        function connectWebSocket() {
            const wsUrl = `ws://${window.location.host}/ws/realtime`;
            websocket = new WebSocket(wsUrl);
            
            websocket.onopen = function(event) {
                isConnected = true;
                updateWebSocketStatus('Connected', 'connected');
                updateRealtimeMessage('‚úÖ Connected to server successfully');
                enableRealtimeControls(true);
            };
            
            websocket.onmessage = function(event) {
                const message = JSON.parse(event.data);
                
                // Show user-friendly messages based on message type
                if (message.type === 'response.done' && message.response) {
                    const output = message.response.output?.[0]?.content?.[0]?.text || 'No response received';
                    updateOutput(`ü§ñ AI Response: ${output}\n`);
                    updateRealtimeMessage(`‚úÖ Response received from AI`);
                } else if (message.type === 'error') {
                    updateRealtimeMessage(`‚ùå Server error: ${message.error?.message || 'Unknown error'}`);
                } else if (message.type === 'response.audio_transcript.delta') {
                    updateRealtimeMessage(`üéµ Processing audio...`);
                } else if (message.type === 'conversation.item.created') {
                    updateRealtimeMessage(`‚úÖ Message processed by server`);
                } else {
                    // For other message types, show a generic confirmation
                    updateRealtimeMessage(`üì® Server response received`);
                }
            };
            
            websocket.onclose = function(event) {
                isConnected = false;
                updateWebSocketStatus('Disconnected', 'ready');
                updateRealtimeMessage('‚ùå Disconnected from server');
                enableRealtimeControls(false);
            };
            
            websocket.onerror = function(error) {
                updateRealtimeMessage(`‚ùå Connection error. Please try reconnecting.`);
                updateOutput(`‚ùå Connection Error: Unable to connect to server\n`);
            };
        }

        function disconnectWebSocket() {
            if (websocket) {
                websocket.close();
            }
        }

        function updateWebSocketStatus(text, status) {
            const statusElement = document.getElementById('wsStatusText');
            const statusContainer = document.getElementById('wsStatus');
            
            statusElement.textContent = text;
            statusContainer.className = `status-indicator status-${status}`;
            
            document.getElementById('connectBtn').disabled = isConnected;
            document.getElementById('disconnectBtn').disabled = !isConnected;
        }

        function enableRealtimeControls(enabled) {
            const controls = [
                'sendTextBtn', 'sendAudioBtn', 'sendImageBtn', 'sendVideoBtn',
                'realtimeAudioFile', 'realtimeImageFile', 'realtimeVideoFile',
                'realtimeVideoPrompt', 'videoStreamBtn', 'screenAnalysisPrompt', 'frameInterval', 'imageQuality', 'changeThreshold', 'testCaptureBtn',
                'realtimeRecordBtn'
            ];
            
            controls.forEach(id => {
                const element = document.getElementById(id);
                if (element) {
                    element.disabled = !enabled;
                }
            });
        }

        function updateRealtimeMessage(message) {
            const messagesDiv = document.getElementById('realtimeMessages');
            // Sanitize message to avoid displaying long binary data
            const sanitizedMessage = sanitizeDisplayMessage(message);
            messagesDiv.textContent += `[${new Date().toLocaleTimeString()}] ${sanitizedMessage}\n`;
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }

        function sanitizeDisplayMessage(message) {
            // Simple sanitization for user-friendly messages
            if (typeof message === 'string') {
                if (message.length > 500) {
                    // Truncate very long strings
                    return message.substring(0, 500) + `... <message truncated>`;
                }
                return message;
            }
            
            return String(message);
        }

        // Real-time sending functions
        function sendRealtimeText() {
            const text = document.getElementById('realtimeTextInput').value;
            if (!text.trim() || !isConnected) return;
            
            const message = {
                event_id: `text_${Date.now()}`,
                type: 'conversation.item.create',
                item: {
                    id: `item_${Date.now()}`,
                    type: 'message',
                    role: 'user',
                    content: [{ type: 'text', text: text }]
                }
            };
            
            websocket.send(JSON.stringify(message));
            updateRealtimeMessage(`üì§ Sent text: ${text}`);
            
            // Request response
            setTimeout(() => {
                const responseRequest = {
                    event_id: `response_${Date.now()}`,
                    type: 'response.create'
                };
                websocket.send(JSON.stringify(responseRequest));
            }, 100);
        }

        // Helper function for efficient base64 conversion
        function arrayBufferToBase64(buffer) {
            const bytes = new Uint8Array(buffer);
            let binary = '';
            const chunkSize = 8192; // Process in chunks to avoid stack overflow
            
            for (let i = 0; i < bytes.length; i += chunkSize) {
                const chunk = bytes.slice(i, i + chunkSize);
                binary += String.fromCharCode.apply(null, chunk);
            }
            
            return btoa(binary);
        }

        async function sendRealtimeAudio() {
            const fileInput = document.getElementById('realtimeAudioFile');
            
            if (!fileInput) {
                updateRealtimeMessage('‚ùå Audio file input not found');
                return;
            }
            
            if (!fileInput.files[0]) {
                updateRealtimeMessage('‚ùå Please select an audio file');
                return;
            }
            
            if (!isConnected) {
                updateRealtimeMessage('‚ùå Please connect to the server first');
                return;
            }
            
            try {
                const file = fileInput.files[0];
                updateRealtimeMessage(`üì§ Sending audio file: ${file.name}`);
                
                const arrayBuffer = await file.arrayBuffer();
                const base64 = arrayBufferToBase64(arrayBuffer);
                
                const message = {
                    event_id: `audio_${Date.now()}`,
                    type: 'conversation.item.create',
                    item: {
                        id: `item_${Date.now()}`,
                        type: 'message',
                        role: 'user',
                        content: [{ type: 'audio', audio: base64 }]
                    }
                };
                
                websocket.send(JSON.stringify(message));
                updateRealtimeMessage(`‚úÖ Audio file sent successfully`);
                
                // Request response
                setTimeout(() => {
                    const responseRequest = {
                        event_id: `response_${Date.now()}`,
                        type: 'response.create'
                    };
                    websocket.send(JSON.stringify(responseRequest));
                }, 100);
            } catch (error) {
                updateRealtimeMessage(`‚ùå Failed to send audio file: ${error.message}`);
            }
        }

        async function sendRealtimeImage() {
            const fileInput = document.getElementById('realtimeImageFile');
            
            if (!fileInput) {
                updateRealtimeMessage('‚ùå Image file input not found');
                return;
            }
            
            if (!fileInput.files[0]) {
                updateRealtimeMessage('‚ùå Please select an image file');
                return;
            }
            
            if (!isConnected) {
                updateRealtimeMessage('‚ùå Please connect to the server first');
                return;
            }
            
            try {
                const file = fileInput.files[0];
                updateRealtimeMessage(`üì§ Sending image file: ${file.name}`);
                
                const arrayBuffer = await file.arrayBuffer();
                const base64 = arrayBufferToBase64(arrayBuffer);
                
                const message = {
                    event_id: `image_${Date.now()}`,
                    type: 'conversation.item.create',
                    item: {
                        id: `item_${Date.now()}`,
                        type: 'message',
                        role: 'user',
                        content: [{ type: 'image', image: base64 }]
                    }
                };
                
                websocket.send(JSON.stringify(message));
                updateRealtimeMessage(`‚úÖ Image file sent successfully`);
                
                // Request response
                setTimeout(() => {
                    const responseRequest = {
                        event_id: `response_${Date.now()}`,
                        type: 'response.create'
                    };
                    websocket.send(JSON.stringify(responseRequest));
                }, 100);
            } catch (error) {
                updateRealtimeMessage(`‚ùå Failed to send image file: ${error.message}`);
            }
        }

        async function sendRealtimeVideo() {
            const fileInput = document.getElementById('realtimeVideoFile');
            const promptInput = document.getElementById('realtimeVideoPrompt');
            
            if (!fileInput) {
                updateRealtimeMessage('‚ùå Video file input not found');
                return;
            }
            
            if (!fileInput.files[0]) {
                updateRealtimeMessage('‚ùå Please select a video file');
                return;
            }
            
            if (!isConnected) {
                updateRealtimeMessage('‚ùå Please connect to the server first');
                return;
            }
            
            try {
                const file = fileInput.files[0];
                const prompt = promptInput ? promptInput.value : 'Analyze this video';
                updateRealtimeMessage(`üì§ Sending video file: ${file.name} (${(file.size / 1024 / 1024).toFixed(2)} MB)`);
                
                const arrayBuffer = await file.arrayBuffer();
                const base64 = arrayBufferToBase64(arrayBuffer);
                
                // Send video with custom prompt
                const message = {
                    event_id: `video_${Date.now()}`,
                    type: 'conversation.item.create',
                    item: {
                        id: `item_${Date.now()}`,
                        type: 'message',
                        role: 'user',
                        content: [
                            { type: 'video', video: base64 },
                            { type: 'text', text: prompt }
                        ]
                    }
                };
                
                websocket.send(JSON.stringify(message));
                updateRealtimeMessage(`‚úÖ Video file sent successfully`);
                
                // Request response
                setTimeout(() => {
                    const responseRequest = {
                        event_id: `response_${Date.now()}`,
                        type: 'response.create'
                    };
                    websocket.send(JSON.stringify(responseRequest));
                }, 100);
            } catch (error) {
                updateRealtimeMessage(`‚ùå Failed to send video file: ${error.message}`);
            }
        }

        // Screen sharing functionality
        let videoStreamSocket = null;
        let isVideoStreamConnected = false;
        let screenStream = null;
        let screenVideo = null;
        let screenCanvas = null;
        let screenContext = null;
        let frameIntervalId = null;
        let frameCounter = 0;
        let lastFrameChecksum = null;

        async function startScreenShare() {
            try {
                // Request screen sharing permission with optimized settings
                screenStream = await navigator.mediaDevices.getDisplayMedia({
                    video: {
                        width: { ideal: 1280, max: 1920 },  // Optimized: 1280p is good balance
                        height: { ideal: 720, max: 1080 },   // Optimized: 720p reduces data while maintaining quality
                        frameRate: { ideal: 5, max: 8 }     // Optimized: Lower framerate for analysis (not real-time video)
                    },
                    audio: false
                });

                // Connect to video streaming WebSocket
                if (!videoStreamSocket) {
                    await connectToVideoStream();
                }

                // Set up video element for screen capture
                screenVideo = document.createElement('video');
                screenVideo.srcObject = screenStream;
                screenVideo.autoplay = true;
                screenVideo.muted = true;
                screenVideo.playsInline = true;
                // Optimized video preview - smaller and less intrusive
                screenVideo.style.position = 'fixed';
                screenVideo.style.bottom = '10px';
                screenVideo.style.right = '10px';
                screenVideo.style.width = '160px';     // Smaller preview
                screenVideo.style.height = '90px';     // Maintains 16:9 aspect ratio
                screenVideo.style.border = '1px solid #4299e1';
                screenVideo.style.borderRadius = '6px';
                screenVideo.style.zIndex = '9999';
                screenVideo.style.backgroundColor = '#000';
                screenVideo.style.opacity = '0.8';     // Semi-transparent
                screenVideo.style.cursor = 'pointer';
                document.body.appendChild(screenVideo);

                // Set up canvas for frame extraction
                screenCanvas = document.createElement('canvas');
                screenContext = screenCanvas.getContext('2d');

                // Wait for video to be ready and playing
                screenVideo.onloadedmetadata = function() {
                    updateRealtimeMessage(`üìπ Video metadata loaded: ${screenVideo.videoWidth}x${screenVideo.videoHeight}`);
                };

                screenVideo.oncanplay = function() {
                    updateRealtimeMessage('üìπ Video can start playing');
                };

                screenVideo.onplaying = function() {
                    // Optimize canvas size for AI analysis (max 1280x720 for efficiency)
                    const maxWidth = 1280;
                    const maxHeight = 720;
                    const aspectRatio = screenVideo.videoWidth / screenVideo.videoHeight;
                    
                    if (screenVideo.videoWidth > maxWidth || screenVideo.videoHeight > maxHeight) {
                        if (aspectRatio > maxWidth / maxHeight) {
                            screenCanvas.width = maxWidth;
                            screenCanvas.height = Math.round(maxWidth / aspectRatio);
                        } else {
                            screenCanvas.height = maxHeight;
                            screenCanvas.width = Math.round(maxHeight * aspectRatio);
                        }
                    } else {
                        screenCanvas.width = screenVideo.videoWidth;
                        screenCanvas.height = screenVideo.videoHeight;
                    }
                    
                    updateVideoStreamStatus('Screen sharing active', 'status-ready');
                    updateRealtimeMessage(`‚úÖ Screen sharing active - Video: ${screenVideo.videoWidth}x${screenVideo.videoHeight} ‚Üí Canvas: ${screenCanvas.width}x${screenCanvas.height}`);
                    
                    // Wait a bit more before starting frame analysis to ensure video is stable
                    setTimeout(() => {
                        startFrameAnalysis();
                    }, 1000);
                    
                    document.getElementById('videoStreamBtn').disabled = true;
                    document.getElementById('videoDisconnectBtn').disabled = false;
                };

                // Force play the video (some browsers need this)
                screenVideo.play().catch(e => {
                    updateRealtimeMessage(`‚ùå Video play error: ${e.message}`);
                });

                // Handle screen share end (user clicks browser's stop sharing)
                screenStream.getVideoTracks()[0].onended = function() {
                    stopScreenShare();
                };

            } catch (error) {
                updateRealtimeMessage(`‚ùå Screen sharing error: ${error.message}`);
                updateVideoStreamStatus('Screen sharing failed', 'status-processing');
            }
        }

        async function connectToVideoStream() {
            return new Promise((resolve, reject) => {
                const wsUrl = `ws://${window.location.host}/ws/realtime/video`;
                videoStreamSocket = new WebSocket(wsUrl);
                
                videoStreamSocket.onopen = function(event) {
                    isVideoStreamConnected = true;
                    updateRealtimeMessage('‚úÖ Connected to video analysis server');
                    resolve();
                };
                
                videoStreamSocket.onmessage = function(event) {
                    const message = JSON.parse(event.data);
                    
                    if (message.type === 'video_stream.connected') {
                        updateRealtimeMessage(`üñ•Ô∏è Screen analysis ready`);
                    } else if (message.type === 'video_frame.analyzed') {
                        updateRealtimeMessage(`üñ•Ô∏è Screen frame ${message.frame_id} analyzed`);
                        updateOutput(`üñ•Ô∏è Screen Analysis: ${message.analysis}\n`);
                    } else if (message.type === 'error') {
                        updateRealtimeMessage(`‚ùå Analysis error: ${message.message}`);
                    }
                };
                
                videoStreamSocket.onclose = function(event) {
                    isVideoStreamConnected = false;
                    videoStreamSocket = null;
                };
                
                videoStreamSocket.onerror = function(error) {
                    updateRealtimeMessage('‚ùå Connection to video analysis server failed');
                    reject(error);
                };
            });
        }

        function startFrameAnalysis() {
            const interval = parseInt(document.getElementById('frameInterval').value);
            
            frameIntervalId = setInterval(() => {
                captureAndAnalyzeFrame();
            }, interval);
            
            updateRealtimeMessage(`üñ•Ô∏è Frame analysis started (every ${interval/1000} seconds)`);
        }

        function captureAndAnalyzeFrame() {
            if (!screenVideo || !screenCanvas || !screenContext || !isVideoStreamConnected) {
                updateRealtimeMessage('‚ùå Frame capture skipped - components not ready');
                return;
            }

            // Check if video is actually playing
            if (screenVideo.paused || screenVideo.ended || screenVideo.readyState < 2) {
                updateRealtimeMessage(`‚ùå Video not ready: paused=${screenVideo.paused}, ended=${screenVideo.ended}, readyState=${screenVideo.readyState}`);
                return;
            }

            try {
                // Clear canvas first
                screenContext.clearRect(0, 0, screenCanvas.width, screenCanvas.height);
                
                // Draw current video frame to canvas
                screenContext.drawImage(screenVideo, 0, 0, screenCanvas.width, screenCanvas.height);
                
                // Check if we actually drew something and detect changes
                const sampleSize = Math.min(100, screenCanvas.width, screenCanvas.height);
                const imageData = screenContext.getImageData(0, 0, sampleSize, sampleSize);
                const pixels = imageData.data;
                let hasContent = false;
                let checksum = 0;
                
                // Check if there are non-black pixels and calculate simple checksum
                for (let i = 0; i < pixels.length; i += 4) {
                    const r = pixels[i], g = pixels[i + 1], b = pixels[i + 2];
                    if (r > 0 || g > 0 || b > 0) {
                        hasContent = true;
                    }
                    // Simple checksum for change detection (sample every 16th pixel)
                    if (i % 64 === 0) {
                        checksum += r + g + b;
                    }
                }
                
                if (!hasContent) {
                    updateRealtimeMessage(`‚ùå Captured frame appears to be black - video may not be ready`);
                    return;
                }
                
                // Skip analysis if frame hasn't changed significantly (percentage-based)
                if (lastFrameChecksum !== null && lastFrameChecksum > 0) {
                    const changeThreshold = parseFloat(document.getElementById('changeThreshold').value);
                    
                    // If threshold is 0, change detection is disabled
                    if (changeThreshold > 0) {
                        const changePercentage = Math.abs(checksum - lastFrameChecksum) / lastFrameChecksum;
                        const thresholdDecimal = changeThreshold / 100;
                        
                        if (changePercentage < thresholdDecimal) {
                            updateRealtimeMessage(`‚è≠Ô∏è Frame ${frameCounter + 1} skipped - change: ${(changePercentage * 100).toFixed(1)}% (< ${changeThreshold}% threshold)`);
                            return;
                        } else {
                            updateRealtimeMessage(`üì∏ Frame ${frameCounter + 1} - change: ${(changePercentage * 100).toFixed(1)}% (‚â• ${changeThreshold}% threshold)`);
                        }
                    } else {
                        updateRealtimeMessage(`üì∏ Frame ${frameCounter + 1} - change detection disabled`);
                    }
                }
                lastFrameChecksum = checksum;
                
                // Convert canvas to blob with optimized compression
                screenCanvas.toBlob(async (blob) => {
                    if (blob && blob.size > 1000) { // Ensure we have a reasonable blob size
                        frameCounter++;
                        const arrayBuffer = await blob.arrayBuffer();
                        const prompt = document.getElementById('screenAnalysisPrompt').value || 'Describe what you see on the screen';
                        
                        // Calculate compression ratio for monitoring
                        const compressionRatio = ((screenCanvas.width * screenCanvas.height * 3) / blob.size).toFixed(1);
                        updateRealtimeMessage(`üì∏ Frame ${frameCounter} (${(blob.size/1024).toFixed(1)}KB, ${compressionRatio}x compressed) - analyzing...`);
                        await sendVideoFrame(arrayBuffer, frameCounter, prompt);
                    } else {
                        updateRealtimeMessage(`‚ùå Invalid blob: size=${blob ? blob.size : 'null'} bytes`);
                    }
                }, 'image/jpeg', parseFloat(document.getElementById('imageQuality').value));  // User-configurable quality
                
            } catch (error) {
                updateRealtimeMessage(`‚ùå Frame capture error: ${error.message}`);
                console.error('Frame capture error:', error);
            }
        }

        function stopScreenShare() {
            // Stop frame analysis
            if (frameIntervalId) {
                clearInterval(frameIntervalId);
                frameIntervalId = null;
            }

            // Stop screen stream
            if (screenStream) {
                screenStream.getTracks().forEach(track => track.stop());
                screenStream = null;
            }

            // Clean up video element
            if (screenVideo) {
                screenVideo.remove();
                screenVideo = null;
            }

            // Clean up canvas
            screenCanvas = null;
            screenContext = null;

            // Close WebSocket
            if (videoStreamSocket) {
                videoStreamSocket.close();
            }

            // Reset UI
            isVideoStreamConnected = false;
            frameCounter = 0;
            updateVideoStreamStatus('Screen sharing stopped', 'status-processing');
            updateRealtimeMessage('‚èπÔ∏è Screen sharing stopped');
            
            document.getElementById('videoStreamBtn').disabled = false;
            document.getElementById('videoDisconnectBtn').disabled = true;
        }

        function updateVideoStreamStatus(text, statusClass) {
            const statusDiv = document.getElementById('videoStreamStatus');
            if (statusDiv) {
                statusDiv.textContent = text;
                statusDiv.className = `status-indicator ${statusClass}`;
                statusDiv.style.display = 'block';
            }
        }

        function testFrameCapture() {
            if (!screenVideo || !screenCanvas || !screenContext) {
                updateRealtimeMessage('‚ùå Test failed - components not initialized');
                return;
            }

            updateRealtimeMessage(`üß™ Testing frame capture...`);
            updateRealtimeMessage(`üìπ Video state: playing=${!screenVideo.paused}, ended=${screenVideo.ended}, readyState=${screenVideo.readyState}`);
            updateRealtimeMessage(`üìπ Video dimensions: ${screenVideo.videoWidth}x${screenVideo.videoHeight}`);
            updateRealtimeMessage(`üìπ Canvas dimensions: ${screenCanvas.width}x${screenCanvas.height}`);

            try {
                // Clear canvas and draw frame
                screenContext.clearRect(0, 0, screenCanvas.width, screenCanvas.height);
                screenContext.drawImage(screenVideo, 0, 0, screenCanvas.width, screenCanvas.height);

                // Sample some pixels
                const centerX = Math.floor(screenCanvas.width / 2);
                const centerY = Math.floor(screenCanvas.height / 2);
                const centerPixel = screenContext.getImageData(centerX, centerY, 1, 1).data;
                updateRealtimeMessage(`üîç Center pixel: R=${centerPixel[0]}, G=${centerPixel[1]}, B=${centerPixel[2]}, A=${centerPixel[3]}`);

                // Create a small test image to verify the canvas works
                const testCanvas = document.createElement('canvas');
                testCanvas.width = 200;
                testCanvas.height = 200;
                const testCtx = testCanvas.getContext('2d');
                
                // Draw the captured frame scaled down
                testCtx.drawImage(screenCanvas, 0, 0, 200, 200);
                
                // Create a data URL for visual inspection
                const dataUrl = testCanvas.toDataURL('image/jpeg', 0.9);
                updateRealtimeMessage(`üìä Test image data URL length: ${dataUrl.length} chars`);
                
                // Show if the data URL contains actual image data (not just a black image)
                if (dataUrl.length > 5000) {
                    updateRealtimeMessage(`‚úÖ Test capture appears to contain image data`);
                } else {
                    updateRealtimeMessage(`‚ùå Test capture appears to be empty/black`);
                }

            } catch (error) {
                updateRealtimeMessage(`‚ùå Test error: ${error.message}`);
                console.error('Test capture error:', error);
            }
        }

        // Send video to streaming endpoint
        async function sendVideoToStream(videoFile, prompt = 'Analyze this video') {
            if (!isVideoStreamConnected || !videoStreamSocket) {
                updateRealtimeMessage('‚ùå Video stream not connected');
                return;
            }
            
            try {
                const arrayBuffer = await videoFile.arrayBuffer();
                const base64 = arrayBufferToBase64(arrayBuffer);
                
                const message = {
                    type: 'video_complete',
                    video: base64,
                    prompt: prompt,
                    timestamp: Date.now()
                };
                
                videoStreamSocket.send(JSON.stringify(message));
                updateRealtimeMessage(`üì§ Video sent to streaming endpoint: ${videoFile.name}`);
            } catch (error) {
                updateRealtimeMessage(`‚ùå Failed to send video to stream: ${error.message}`);
            }
        }

        // Send individual video frame
        async function sendVideoFrame(frameData, frameId, prompt = 'Describe this video frame') {
            if (!isVideoStreamConnected || !videoStreamSocket) {
                updateRealtimeMessage('‚ùå Video stream not connected');
                return;
            }
            
            try {
                const base64 = arrayBufferToBase64(frameData);
                
                const message = {
                    type: 'video_frame',
                    frame: base64,
                    frame_id: frameId,
                    prompt: prompt,
                    timestamp: Date.now()
                };
                
                videoStreamSocket.send(JSON.stringify(message));
                updateRealtimeMessage(`üì§ Video frame ${frameId} sent for analysis`);
            } catch (error) {
                updateRealtimeMessage(`‚ùå Failed to send video frame: ${error.message}`);
            }
        }

        // Real-time recording
        async function startRealtimeRecording() {
            if (!isConnected) return;
            
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                realtimeRecordedChunks = [];
                realtimeMediaRecorder = new MediaRecorder(stream);
                
                realtimeMediaRecorder.ondataavailable = function(event) {
                    if (event.data.size > 0) {
                        realtimeRecordedChunks.push(event.data);
                    }
                };
                
                realtimeMediaRecorder.onstop = function() {
                    stream.getTracks().forEach(track => track.stop());
                    sendRealtimeRecording();
                };
                
                realtimeMediaRecorder.start();
                
                document.getElementById('realtimeRecordBtn').disabled = true;
                document.getElementById('realtimeStopBtn').disabled = false;
                
                updateRealtimeMessage('üéôÔ∏è Real-time recording started...');
                
            } catch (error) {
                updateRealtimeMessage(`‚ùå Recording Error: ${error.message}`);
            }
        }

        function stopRealtimeRecording() {
            if (realtimeMediaRecorder && realtimeMediaRecorder.state === 'recording') {
                realtimeMediaRecorder.stop();
                
                document.getElementById('realtimeRecordBtn').disabled = false;
                document.getElementById('realtimeStopBtn').disabled = true;
                
                updateRealtimeMessage('‚èπÔ∏è Real-time recording stopped, sending...');
            }
        }
        
        async function sendRealtimeRecording() {
            const audioBlob = new Blob(realtimeRecordedChunks, { type: 'audio/webm' });
            const arrayBuffer = await audioBlob.arrayBuffer();
            const base64 = arrayBufferToBase64(arrayBuffer);
            
            const message = {
                event_id: `live_audio_${Date.now()}`,
                type: 'conversation.item.create',
                item: {
                    id: `item_${Date.now()}`,
                    type: 'message',
                    role: 'user',
                    content: [{ type: 'audio', audio: base64 }]
                }
            };
            
            websocket.send(JSON.stringify(message));
            updateRealtimeMessage('üì§ Sent live recording');
            
            // Request response
            setTimeout(() => {
                const responseRequest = {
                    event_id: `response_${Date.now()}`,
                    type: 'response.create'
                };
                websocket.send(JSON.stringify(responseRequest));
            }, 100);
        }
    </script>
</body>
</html> 